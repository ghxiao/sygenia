1) BRIEF DESCRIPTION

SyGENiA is a prototypical tool for the automatic generation of (testing) data (i.e., instance axioms/facts/ABoxes) as well as Conjunctive Queries (CQs) for Semantic Web ontologies written in OWL or RDF(S). SyGENiA can generate a collection of data for each given query and ontologies in order to test completeness of a (tested) system for the specific query and ontology. SyGENiA is also able to duplicate the set of generated (completeness testing) data in order to generate large datasets for the purposes of evaluating performance and scalability, however, there is no well-developed theory behind this duplication methods. Finally, SyGENiA is also able to generate test conjunctive queries given only an ontology as input.

2) TEST GENERATION

2.1) Data Generation for Completeness Evaluation

Assume an ontology schema (i.e., a TBox) and a set of Conjunctive Queries constructed for some Semantic Web application. SyGENiA is able to generate for each query for the given ontology schema datasets that are "relevant" for this schema and each query---that is, the generated data together with the ontology provide answers to the input query for which the data have been generated. In other words the generated data are not random. The goal of SyGENiA is to enable Semantic Web application developers to automatically generate testing data for their application scenarios (ontologies + queries). For example, the generated data together with the ontology schema and queries can then be fed to Semantic Web Query Answering systems in order to evaluate them and assess with a higher degree of confidence which system is the most appropriate for the specific application. It has been theoretically shown that, if a system is able to handle all the data generated by SyGENiA (i.e. it is complete for these data) then it will be able to handle any arbitrary input data for the input ontology and query (i.e. it is complete for this query and TBox regardless of the input data).

SyGENiA is guaranteed to generate *all* relevant data patterns for the ELHI part of an input ontology.  

The theory behind data generation for given ontologies (TBoxes) and Conjunctive Queries (CQs) and for the purposes of testing completeness of Semantic Web Reasoners has been described in the following papers:

[1] Bernardo Cuenca Grau, Boris Motik, Giorgos Stoilos, and Ian Horrocks. Completeness Guarantees for Incomplete Ontology Reasoners: Theory and
Practice. Accepted for publication at the Journal of Artificial Intelligence Research.

[2] Giorgos Stoilos, Bernardo Cuenca Grau, and Ian Horrocks. How Incomplete is Your Semantic Web Reasoner. In Proceedings of 24th AAAI Conference on Artificial Intelligence (AAAI 2010). Pages 1431−1436.

[3] Giorgos Stoilos, Bernardo Cuenca Grau, and Ian Horrocks. Completeness Guarantees for Incomplete Reasoners. In Proceedings of the Ninth International Semantic Web Conference (ISWC 2010). 2010. 

Note that the current structure and naming of methods of the software are aligned with the journal paper [1] and is a bit different from previous versions of SyGENiA.

2.2) Data Generation for Performance Evaluation

SyGENiA is also able to create arbitrary large datasets. These datasets can be used for performance evaluation, however, this functionality of the software is still under development and no assumptions should be made. That is, the techniques used to generate these large ABoxes are not based on an well-defined theory.

2.3) Query Generation for Completeness Evaluation

Last but not least, given only an ontology as input, SyGENiA is able to generate (test) conjunctive queries for the given ontology. Subsequently, the user can use the data generation techniques to generate ABoxes for each of the generated queries. If a tested systems is complete for each of the generated datasets for each of the generated queries, then it will be complete wrt any conjunctive query and any input data for the given ontology schema. The theory behind the query generation has been published in the following paper.

[4] Bernardo Cuenca Grau and Giorgos Stoilos. What to Ask to an Incomplete Semantic Web Reasoner?. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI−2011). 2011. 

3) INSTALLATION

The software is comprised of three JAVA .jar files that can be found in the folder /lib. Include these jar files in your JAVA classpath when running the tool.

4) QUICK START

The source code of the tool is also available under folder /src. 

In folder /src/examples you can find three examples that show how you can run the tool to either generate tests for the purposes of completeness evaluation (many small test ABoxes), or large ABoxes for the purposes of performance and scalability evaluation, or a set of conjunctive queries for the given ontology schema. The two data generation examples are built around two sample application scenarios. One is based on the well-known LUBM ontology and the other one on the also well-known Galen ontology. These scenarios (ontologies plus queries) can be found under the folder /examples/ontologies/. The query generation example uses many input ontology schemas that can be found under /examples/ontologies/QueryGeneration/.

==== 3. BRIEF DESCRIPTION OF CODE ====

3.1 DATA GENERATION

The Data generation methods can be found in the package org.oxford.comlab.aBoxGeneration. There are mainly two important classes in this package. 

a) The first one is TestSuiteGenerator, which is responsible for the generation of Test Suite for a given query and TBox (i.e. a the exhaustive set of ABoxes). 

b) The second class is LargeABoxGenerator, which is used to generate large ABoxes for a given TBox and conjunctive query. The user needs to specify how many assertions would like LargeABoxGenerator to generate for the TBox and query, or how many certain answers would like the final ABox to give. The user should also specify the maximum number of individuals that the generation method should consider when generating the assertions. 

3.2 COMPLETENESS ANALYSIS

To analyse the completeness of a system one needs to feed one-by-one the members of a generated dataset, together with the query and ontology for which the dataset has been generated. Then query the system and check whether the system returns any answers. A sample set of completeness analysing classes is provided in package org.oxford.comlab.compass. The class CompletenessAnalyser loads the ABoxes one-by-one into a system and runs the query. If the system returns at-least one certain answer the test is considered successful, otherwise it is considered failed. A tested system must implement the SystemInterface interface in order for the CompletenessAnalyser class to interact with the tested system and load and execute the tests.

**** Example ****

Assume you have ran the ExampleTestSuite.java class over LUBM. This would create a test suite for each query under the folder $PATH/examples/ontologies/LUBM/univ-bench_TB-C_s

The following is then a sample way to use the CompletenessAnalyser over these testing bases:

String ontologyFile = "$PATH/examples/ontologies/LUBM/univ-bench.owl";
String datasetFolder = "/$PATH/examples/ontologies/LUBM/univ-bench_TB-C_s

CompletenessAnalyser complAnalyzer = new CompletenessAnalyser();
MySystemInterfaceImplementation mySystem = new MySystemInterfaceImplementation();

complAnalyzer.doCompletenessAnalysisExperimentAllMappings( mySystem, ontologyFile, datasetFolder );

CompletenessAnalyser will then go through all sub-folders of folder "datasetFolder" and load each test suite that exists there. Be careful when CompletenessAnalsyser loads the i-th testing base for the i-th query your MySystemInterfaceImplementation needs to also load the i-th query to the system. 


3.3 QUERY GENERATION

The query generation methods can be found in the package org.oxford.comlab.querygenerator. The main class is QTBGenerator which generates a Query Testing Base [3] given an input ontology.

3.4 COMPLETENESS IMPROVEMENT

Package org.oxford.comlab.tBoxRewriting provides experimental software for the improvement of the completeness of incomplete systems as this has been presented in the following paper

[5] Giorgos Stoilos, Bernardo Cuenca Grau, Boris Motik, and Ian Horrocks. Repairing Ontologies for Incomplete Reasoners. ISWC 2011.

This software is still under development.
